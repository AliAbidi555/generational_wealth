{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "- [Import Packages](#Packages)\n",
    "- [Data Cleaning](#Data-Cleaning)\n",
    "- [Data Exploration](#Data-Exploration)\n",
    "- [Models](#Models)\n",
    "    - [OLS](#OLS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import csv\n",
    "import subprocess\n",
    "import psutil\n",
    "from datetime import datetime\n",
    "from fuzzywuzzy import fuzz,process\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from feature_engine.imputation import CategoricalImputer\n",
    "\n",
    "from boruta import BorutaPy\n",
    "\n",
    "from fancyimpute import KNN\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier,RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score, roc_auc_score, recall_score,confusion_matrix, ConfusionMatrixDisplay,roc_curve\n",
    "from sklearn.inspection import PartialDependenceDisplay\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "import category_encoders as ce\n",
    "import zipfile\n",
    "import sweetviz as sv\n",
    "\n",
    "import xgboost as xgb\n",
    "import optuna\n",
    "import optuna.visualization as vis\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "edu_mapping = {\n",
    "    \"000\": 0,   # NIU or no schooling\n",
    "    \"001\": 0,   # NIU or blank\n",
    "    \"002\": 0,   # None, preschool, or kindergarten\n",
    "\n",
    "    # Grades 1–8\n",
    "    \"010\": 2,\n",
    "    \"011\": 1,\n",
    "    \"012\": 2,\n",
    "    \"013\": 3,\n",
    "    \"014\": 4,\n",
    "    \"020\": 5,\n",
    "    \"021\": 5,\n",
    "    \"022\": 6,\n",
    "    \"030\": 7,\n",
    "    \"031\": 7,\n",
    "    \"032\": 8,\n",
    "\n",
    "    # High school\n",
    "    \"040\": 9,\n",
    "    \"050\": 10,\n",
    "    \"060\": 11,\n",
    "    \"070\": 12,\n",
    "    \"071\": 11,\n",
    "    \"072\": 12,\n",
    "    \"073\": 12,\n",
    "\n",
    "    # College\n",
    "    \"080\": 13,\n",
    "    \"081\": 13,\n",
    "    \"090\": 14,\n",
    "    \"091\": 14,\n",
    "    \"092\": 14,\n",
    "    \"100\": 15,\n",
    "    \"110\": 16,\n",
    "    \"111\": 16,\n",
    "    \"112\": 17,\n",
    "    \"120\": 17,\n",
    "    \"121\": 18,\n",
    "    \"123\": 18,\n",
    "    \"124\": 19,\n",
    "    \"125\": 20,\n",
    "\n",
    "    # Missing\n",
    "    \"999\": np.nan\n",
    "}\n",
    "\n",
    "def recode_educ_column(series: pd.Series) -> pd.Series:\n",
    "    # Convert to string, zero-fill to length 3, then map with the dictionary\n",
    "    codes_str = series.astype(str).str.zfill(3)\n",
    "    return codes_str.map(edu_mapping).fillna(np.nan)\n",
    "\n",
    "\n",
    "age_bins = [0, 18, 25, 35, 45, 55, 65, np.inf]\n",
    "age_labels = [\"<18\", \"18–24\", \"25–34\", \"35–44\", \"45–54\", \"55–64\", \"65+\"]\n",
    "\n",
    "def pick_two_parents(row):\n",
    "    # Gather all four parent columns into a list\n",
    "    ages = [row[\"AGE_MOM\"], row[\"AGE_MOM2\"], row[\"AGE_POP\"], row[\"AGE_POP2\"]]\n",
    "    valid = [age for age in ages if pd.notna(age)]\n",
    "    \n",
    "    parent1 = valid[0] if len(valid) > 0 else np.nan\n",
    "    parent2 = valid[1] if len(valid) > 1 else np.nan\n",
    "    \n",
    "    return pd.Series([parent1, parent2], index=[\"parent1_age\", \"parent2_age\"])\n",
    "\n",
    "# Apply the function row-by-row\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data-Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"cps_00018.csv\")\n",
    "\n",
    "# Apply the vectorized recode to the EDUC column\n",
    "df[\"EDUC\"] = recode_educ_column(df[\"EDUC\"])\n",
    "\n",
    "\n",
    "\n",
    "### Convert Age into buckets\n",
    "age_cols = [\"AGE_MOM\", \"AGE_MOM2\", \"AGE_POP\", \"AGE_POP2\"]\n",
    "\n",
    "df = df.assign(\n",
    "    **{\n",
    "        f\"{col}_bucket\": pd.cut(\n",
    "            df[col],\n",
    "            bins=age_bins,\n",
    "            labels=age_labels,\n",
    "            right=False\n",
    "        )\n",
    "        for col in age_cols  # e.g. [\"AGE_MOM\",\"AGE_MOM2\",\"AGE_POP\",\"AGE_POP2\"]\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "# Extract those four columns as a NumPy array (N rows x 4 columns)\n",
    "\n",
    "\n",
    "# Prepare empty arrays for the results\n",
    "parent1 = np.full(len(df), np.nan, dtype=object)\n",
    "parent2 = np.full(len(df), np.nan, dtype=object)\n",
    "\n",
    "\n",
    "\n",
    "bucketed_cols = [f\"{col}_bucket\" for col in age_cols]\n",
    "\n",
    "arr = df[bucketed_cols].astype(object).to_numpy()\n",
    "\n",
    "\n",
    "for i in range(len(df)):\n",
    "    row_ages = arr[i]  # e.g., [\"18–24\", np.nan, \"<18\", ...]\n",
    "    valid = [x for x in row_ages if pd.notna(x)]\n",
    "    \n",
    "    if len(valid) > 0:\n",
    "        parent1[i] = valid[0]\n",
    "    if len(valid) > 1:\n",
    "        parent2[i] = valid[1]\n",
    "\n",
    "\n",
    "# Assign the results back to the DataFrame\n",
    "df[\"PARENT1_AGE_BUCKET\"] = parent1\n",
    "df[\"PARENT2_AGE_BUCKET\"] = parent2\n",
    "\n",
    "\n",
    "\n",
    "# List the 4 parent-education columns\n",
    "educ_cols = ['EDUC_MOM', 'EDUC_MOM2', 'EDUC_POP', 'EDUC_POP2']\n",
    "\n",
    "# Convert these columns to a NumPy array (N rows x 4 columns)\n",
    "# Make sure the dtype allows for NaNs (float, object, etc.)\n",
    "arr_educ = df[educ_cols].to_numpy(dtype=float)\n",
    "\n",
    "# Prepare empty arrays for storing the first and second valid education\n",
    "parent1_educ = np.full(len(df), np.nan)\n",
    "parent2_educ = np.full(len(df), np.nan)\n",
    "\n",
    "# Loop over the rows in NumPy (faster than row-by-row .apply() in large datasets)\n",
    "for i in range(len(df)):\n",
    "    row_values = arr_educ[i]\n",
    "    # Filter out NaNs\n",
    "    valid_educs = row_values[~np.isnan(row_values)]\n",
    "    \n",
    "    # Assign up to two valid education codes\n",
    "    if len(valid_educs) > 0:\n",
    "        parent1_educ[i] = valid_educs[0]  # first non-NaN\n",
    "    if len(valid_educs) > 1:\n",
    "        parent2_educ[i] = valid_educs[1]  # second non-NaN\n",
    "\n",
    "# Attach the arrays back to your DataFrame as new columns\n",
    "df[\"PARENT1_EDUC\"] = parent1_educ\n",
    "df[\"PARENT2_EDUC\"] = parent2_educ\n",
    "\n",
    "\n",
    "### Get hourly wage\n",
    "df['hr_wage'] = df['INCWAGE']/df['UHRSWORKT']\n",
    "\n",
    "\n",
    "### Get Tenure\n",
    "df['TENURE'] = df['AGE'] - df['EDUC'] - 7\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "categorical_columns  = [\"SEX\", \"RACE\", \"YEAR\", \"OCC\",'IND1990','AGE_BUCKET','VETSTAT','PARENT1_AGE_BUCKET','PARENT2_AGE_BUCKET']\n",
    "numeric_columns  = [ 'EDUC', 'PARENT1_EDUC','PARENT2_EDUC','TENURE']\n",
    "\n",
    "\n",
    "target_variable  = \"INCWAGE\"  # Dependent variable\n",
    "weight_column  = \"weight\"\n",
    "\n",
    "\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5186113"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data-Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f97a1d4202404a778007b5467f56b857",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "                                             |          | [  0%]   00:00 -> (? left)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report sweetviz_report.html was generated! NOTEBOOK/COLAB USERS: the web browser MAY not pop up, regardless, the report IS saved in your notebook/colab files.\n",
      "---\n",
      "WARNING: one or more correlations had an edge-case/error and a 1.0 correlation was assigned\n",
      "(likely due to only having a single row, containing non-NaN values for both correlated features)\n",
      "Affected correlations:['MONTH/ASECWTH', 'MONTH/HHINCOME', 'MONTH/ASECWT', 'MONTH/INCWAGE', 'ASECWTH/MONTH', 'HHINCOME/MONTH', 'ASECWT/MONTH', 'INCWAGE/MONTH']\n"
     ]
    }
   ],
   "source": [
    "report = sv.analyze(df)\n",
    "report.show_html(\"sweetviz_report.html\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Measure initial resource usage\n",
    "# -------------------------------------------------------------------\n",
    "process = psutil.Process()\n",
    "start_cpu_times = process.cpu_times()\n",
    "mem_info_start = process.memory_info().rss  # Resident Set Size in bytes\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Prepare features (X) and target (y)\n",
    "# -------------------------------------------------------------------\n",
    "# 1. Separate numeric features\n",
    "X_numeric = df[numeric_columns]\n",
    "\n",
    "# 2. Convert categorical columns to string (to avoid issues with non-string types)\n",
    "df_categorical_str = df[categorical_columns].astype(str)\n",
    "\n",
    "# 3. One-hot encode categorical features\n",
    "df_one_hot = pd.get_dummies(df_categorical_str)\n",
    "\n",
    "# 4. Concatenate numeric and one-hot-encoded features\n",
    "X = pd.concat([X_numeric, df_one_hot], axis=1)\n",
    "\n",
    "# 5. Define the target variable (y) and sample weights\n",
    "y = df[target_variable]\n",
    "sample_weight = df[weight_column]\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Fit the linear regression model\n",
    "# -------------------------------------------------------------------\n",
    "model = LinearRegression()\n",
    "model.fit(X, y, sample_weight=sample_weight)\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Evaluate the model (R² score)\n",
    "# -------------------------------------------------------------------\n",
    "r2 = model.score(X, y, sample_weight=sample_weight)\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Measure time and resource usage after model training\n",
    "# -------------------------------------------------------------------\n",
    "end_time = time.time()\n",
    "end_cpu_times = process.cpu_times()\n",
    "mem_info_end = process.memory_info().rss\n",
    "\n",
    "# Calculate the differences\n",
    "run_time = end_time - start_time\n",
    "cpu_time_used = (\n",
    "    (end_cpu_times.user + end_cpu_times.system)\n",
    "    - (start_cpu_times.user + start_cpu_times.system)\n",
    ")\n",
    "mem_used = (mem_info_end - mem_info_start) / (1024 * 1024)  # Convert bytes to MB\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Print out metrics\n",
    "# -------------------------------------------------------------------\n",
    "print(f\"R² Score: {r2:.4f}\")\n",
    "print(f\"Time taken: {run_time:.4f} seconds\")\n",
    "print(f\"CPU time used: {cpu_time_used:.4f} seconds (user + system)\")\n",
    "print(f\"Approx. additional RAM used: {mem_used:.4f} MB\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
