{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "- [Import Packages](#Packages)\n",
    "- [Data Cleaning](#Data-Cleaning)\n",
    "- [Data Exploration](#Data-Exploration)\n",
    "- [Models](#Models)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import csv\n",
    "import subprocess\n",
    "import psutil\n",
    "from datetime import datetime\n",
    "from fuzzywuzzy import fuzz,process\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from feature_engine.imputation import CategoricalImputer\n",
    "\n",
    "from boruta import BorutaPy\n",
    "\n",
    "from fancyimpute import KNN\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier,RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score, roc_auc_score, recall_score,confusion_matrix, ConfusionMatrixDisplay,roc_curve,r2_score\n",
    "from sklearn.inspection import PartialDependenceDisplay\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "import category_encoders as ce\n",
    "import zipfile\n",
    "import sweetviz as sv\n",
    "\n",
    "import xgboost as xgb\n",
    "import optuna\n",
    "import optuna.visualization as vis\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "edu_mapping = {\n",
    "    \"00\": 0,   # NIU (Not in Universe)\n",
    "    \"01\": 0,   # No school completed\n",
    "    \"02\": 0,   # NIU or blank\n",
    "    \"03\": 2,   # 1st-4th grade\n",
    "    \"04\": 4,   # 5th-8th grade\n",
    "    \"05\": 8,   # 9th grade\n",
    "    \"06\": 9,   # 10th grade\n",
    "    \"07\": 10,  # 11th grade\n",
    "    \"08\": 11,  # 12th grade, no diploma\n",
    "    \"09\": 12,  # High school graduate, GED\n",
    "    \"10\": 13,  # Some college, no degree\n",
    "    \"11\": 14,  # Associate degree, type of program not specified\n",
    "    \"12\": 14,  # Associate degree, occupational program\n",
    "    \"13\": 14,  # Associate degree, academic program\n",
    "    \"14\": 16,  # Bachelor's degree\n",
    "    \"15\": 18,  # Master's degree\n",
    "    \"16\": 19,  # Professional degree\n",
    "    \"17\": 20   # Doctorate degree\n",
    "}\n",
    "\n",
    "def recode_educ_column(series: pd.Series) -> pd.Series:\n",
    "    \"\"\"Convert to string, zero-fill to length 3, then map with the dictionary.\"\"\"\n",
    "    return (\n",
    "        series.astype(str)\n",
    "              .str.zfill(3)\n",
    "              .map(edu_mapping)\n",
    "              .astype(float)  # Ensures NaNs are properly handled\n",
    "    )\n",
    "\n",
    "\n",
    "age_bins = [0, 18, 25, 35, 45, 55, 65, np.inf]\n",
    "age_labels = [\"under_18\", \"18–24\", \"25–34\", \"35–44\", \"45–54\", \"55–64\", \"65+\"]\n",
    "\n",
    "def pick_two_parents(row):\n",
    "    # Gather all four parent columns into a list\n",
    "    ages = [row[\"AGE_MOM\"], row[\"AGE_MOM2\"], row[\"AGE_POP\"], row[\"AGE_POP2\"]]\n",
    "    valid = [age for age in ages if pd.notna(age)]\n",
    "    \n",
    "    parent1 = valid[0] if len(valid) > 0 else np.nan\n",
    "    parent2 = valid[1] if len(valid) > 1 else np.nan\n",
    "    \n",
    "    return pd.Series([parent1, parent2], index=[\"parent1_age\", \"parent2_age\"])\n",
    "\n",
    "# Apply the function row-by-row\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data-Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"cps_00018.csv\",nrows = 100000)\n",
    "columns_all_nan = [col for col in df.columns if df[col].isna().all()]\n",
    "print(f\"Columns entirely NaN: {columns_all_nan}\")\n",
    "\n",
    "# Drop columns that are entirely NaN\n",
    "df = df.drop(columns=columns_all_nan)\n",
    "\n",
    "\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 3. Recode education columns in a vectorized way\n",
    "# -------------------------------------------------------\n",
    "# educ_cols = [\"EDUC99_MOM\", \"EDUC99_MOM2\", \"EDUC99_POP\", \"EDUC99_POP2\", \"EDUC99\"]\n",
    "# df[educ_cols] = df[educ_cols].apply(recode_educ_column)\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 4. Convert age into buckets (vectorized with pd.cut)\n",
    "# -------------------------------------------------------\n",
    "age_bins = [0, 18, 25, 35, 45, 55, 65, np.inf]\n",
    "age_labels = [\"under_18\", \"18–24\", \"25–34\", \"35–44\", \"45–54\", \"55–64\", \"65+\"]\n",
    "age_cols = [\"AGE_MOM\", \"AGE_MOM2\", \"AGE_POP\", \"AGE_POP2\", \"AGE\"]\n",
    "\n",
    "for col in age_cols:\n",
    "    new_col = f\"{col}_bucket\"\n",
    "    df[new_col] = pd.cut(\n",
    "        df[col],\n",
    "        bins=age_bins,\n",
    "        labels=age_labels,\n",
    "        right=False\n",
    "    ).astype(\"object\")  # Ensure dtype is object to avoid mismatches\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 5. Extract First Two Valid Parent Age Buckets (Vectorized)\n",
    "# -------------------------------------------------------\n",
    "parent_age_bucket_cols = [\"AGE_MOM_bucket\", \"AGE_MOM2_bucket\", \"AGE_POP_bucket\", \"AGE_POP2_bucket\"]\n",
    "\n",
    "# Extract the relevant columns as a NumPy array\n",
    "parent_age_array = df[parent_age_bucket_cols].values\n",
    "\n",
    "# Initialize arrays to hold the first two valid ages\n",
    "parent1_age = np.full(len(df), np.nan, dtype=object)\n",
    "parent2_age = np.full(len(df), np.nan, dtype=object)\n",
    "\n",
    "# Vectorized extraction using NumPy\n",
    "# Iterate over each row's parent ages\n",
    "for i in range(len(df)):\n",
    "    valid_ages = parent_age_array[i][~pd.isna(parent_age_array[i])]\n",
    "    if len(valid_ages) > 0:\n",
    "        parent1_age[i] = valid_ages[0]\n",
    "    if len(valid_ages) > 1:\n",
    "        parent2_age[i] = valid_ages[1]\n",
    "\n",
    "# Assign to DataFrame with explicit dtype\n",
    "df[\"PARENT1_AGE_BUCKET\"] = parent1_age\n",
    "df[\"PARENT2_AGE_BUCKET\"] = parent2_age\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 6. Pick first two valid parent education codes (vectorized)\n",
    "# -------------------------------------------------------\n",
    "parent_educ_cols = [\"EDUC99_MOM\", \"EDUC99_MOM2\", \"EDUC99_POP\", \"EDUC99_POP2\"]\n",
    "\n",
    "# Verify that all parent education columns exist\n",
    "missing_parent_educ_cols = [col for col in parent_educ_cols if col not in df.columns]\n",
    "if missing_parent_educ_cols:\n",
    "    raise ValueError(f\"The following parent education columns are missing from the DataFrame: {missing_parent_educ_cols}\")\n",
    "\n",
    "# Extract the relevant columns as a NumPy array\n",
    "parent_educ_array = df[parent_educ_cols].values\n",
    "\n",
    "# Initialize arrays to hold the first two valid education codes\n",
    "parent1_educ = np.full(len(df), np.nan, dtype=float)\n",
    "parent2_educ = np.full(len(df), np.nan, dtype=float)\n",
    "for i in range(len(df)):\n",
    "    # Extract non-NaN education codes\n",
    "    valid_educs = parent_educ_array[i][~pd.isna(parent_educ_array[i])]\n",
    "    if len(valid_educs) > 0:\n",
    "        parent1_educ[i] = valid_educs[0]\n",
    "    if len(valid_educs) > 1:\n",
    "        parent2_educ[i] = valid_educs[1]\n",
    "\n",
    "# Assign to DataFrame\n",
    "df[\"PARENT1_EDUC\"] = parent1_educ\n",
    "df[\"PARENT2_EDUC\"] = parent2_educ\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 7. Recode hours worked (replace 999/997 with mean)\n",
    "# -------------------------------------------------------\n",
    "invalid_hours = [999, 997]\n",
    "df[\"UHRSWORKT\"] = df[\"UHRSWORKT\"].replace(invalid_hours, np.nan)\n",
    "mean_hours = df[\"UHRSWORKT\"].mean()\n",
    "df[\"UHRSWORKT\"].fillna(mean_hours, inplace=True)\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 8. Compute hourly wage\n",
    "# -------------------------------------------------------\n",
    "# To avoid division by zero, replace any zero UHRSWORKT with a small number or NaN\n",
    "valid_mean = df.loc[df[\"INCWAGE\"] != 99999999, \"INCWAGE\"].mean()\n",
    "df[\"INCWAGE\"] = df[\"INCWAGE\"].replace(99999999, valid_mean)\n",
    "df[\"UHRSWORKT\"] = df[\"UHRSWORKT\"].replace(0, np.nan)\n",
    "df[\"hr_wage\"] = df[\"INCWAGE\"] / df[\"UHRSWORKT\"]\n",
    "df[\"hr_wage\"].replace([np.inf, -np.inf], np.nan, inplace=True)  # Handle division by zero if any\n",
    "df[\"hr_wage\"].fillna(df[\"hr_wage\"].mean(), inplace=True)  # Replace NaNs resulting from division by zero\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 9. Compute tenure\n",
    "# -------------------------------------------------------\n",
    "df[\"TENURE\"] = df[\"AGE\"] - df[\"EDUC99\"] - 7\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 10. Define columns for your modeling\n",
    "# -------------------------------------------------------\n",
    "categorical_columns = [\n",
    "    \"SEX\", \"RACE\", \"YEAR\",   \"AGE_bucket\",\n",
    "    \"VETSTAT\", \"PARENT1_AGE_BUCKET\", \"PARENT2_AGE_BUCKET\"\n",
    "]\n",
    "numeric_columns = [\"EDUC99\", \"PARENT1_EDUC\", \"PARENT2_EDUC\", \"TENURE\"]\n",
    "\n",
    "target_variable = \"hr_wage\"\n",
    "weight_column = \"ASECWTH\"\n",
    "\n",
    "# (Optional) Quick sanity check\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99999999"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['INCWAGE'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['EDUC99_MOM'].isna().all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data-Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_report = False\n",
    "if create_report:\n",
    "    report = sv.analyze(df)\n",
    "    report.show_html(\"sweetviz_report.html\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-28 14:11:10,032] A new study created in memory with name: no-name-5791aeff-3307-4b4d-bc2c-93f0bb2a9351\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final data checks:\n",
      "Number of samples: 100000\n",
      "Number of features: 30\n",
      "Any NaNs in features: False\n",
      "Any NaNs in target: False\n",
      "\n",
      "===== Linear Regression Performance =====\n",
      "R² Score: 0.9874\n",
      "Time taken: 0.1055 seconds\n",
      "CPU time used: 0.7969 seconds (user + system)\n",
      "Approx. additional RAM used: 0.0000 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-28 14:11:11,909] Trial 0 finished with value: 0.9998267138129874 and parameters: {'n_estimators': 389, 'max_depth': 8, 'learning_rate': 0.18037347501244516, 'subsample': 0.5726551158693429, 'colsample_bytree': 0.5955087150902499}. Best is trial 0 with value: 0.9998267138129874.\n",
      "[I 2025-01-28 14:11:12,429] Trial 1 finished with value: 0.9998580913201494 and parameters: {'n_estimators': 150, 'max_depth': 3, 'learning_rate': 0.06218866507451881, 'subsample': 0.6118279993874646, 'colsample_bytree': 0.8728507966376917}. Best is trial 1 with value: 0.9998580913201494.\n",
      "[I 2025-01-28 14:11:13,689] Trial 2 finished with value: 0.9997207569180964 and parameters: {'n_estimators': 387, 'max_depth': 3, 'learning_rate': 0.013684393800767698, 'subsample': 0.9581641884965826, 'colsample_bytree': 0.5763714597170853}. Best is trial 1 with value: 0.9998580913201494.\n",
      "[I 2025-01-28 14:11:15,271] Trial 3 finished with value: 0.9998658747582126 and parameters: {'n_estimators': 455, 'max_depth': 4, 'learning_rate': 0.03287804027496972, 'subsample': 0.6795646316813646, 'colsample_bytree': 0.7707293840840531}. Best is trial 3 with value: 0.9998658747582126.\n",
      "[I 2025-01-28 14:11:16,029] Trial 4 finished with value: 0.9793951039690278 and parameters: {'n_estimators': 117, 'max_depth': 11, 'learning_rate': 0.017307058147536886, 'subsample': 0.976133922607836, 'colsample_bytree': 0.539939587345572}. Best is trial 3 with value: 0.9998658747582126.\n",
      "[I 2025-01-28 14:11:17,108] Trial 5 finished with value: 0.999629123580875 and parameters: {'n_estimators': 271, 'max_depth': 5, 'learning_rate': 0.017486124081921465, 'subsample': 0.6058494204068308, 'colsample_bytree': 0.5483270947190735}. Best is trial 3 with value: 0.9998658747582126.\n",
      "[I 2025-01-28 14:11:20,869] Trial 6 finished with value: 0.9998560048165788 and parameters: {'n_estimators': 451, 'max_depth': 12, 'learning_rate': 0.07382877344514652, 'subsample': 0.75765333582153, 'colsample_bytree': 0.8809505567457983}. Best is trial 3 with value: 0.9998658747582126.\n",
      "[I 2025-01-28 14:11:23,134] Trial 7 finished with value: 0.9998592761674885 and parameters: {'n_estimators': 349, 'max_depth': 8, 'learning_rate': 0.03993110121200573, 'subsample': 0.7769522679911576, 'colsample_bytree': 0.8849953476926675}. Best is trial 3 with value: 0.9998658747582126.\n",
      "[I 2025-01-28 14:11:24,139] Trial 8 finished with value: 0.9998600770154993 and parameters: {'n_estimators': 287, 'max_depth': 4, 'learning_rate': 0.10154915533160729, 'subsample': 0.5854602159211342, 'colsample_bytree': 0.6007655020688947}. Best is trial 3 with value: 0.9998658747582126.\n",
      "[I 2025-01-28 14:11:25,086] Trial 9 finished with value: 0.999848919512161 and parameters: {'n_estimators': 234, 'max_depth': 6, 'learning_rate': 0.02481320899584009, 'subsample': 0.6174425841057167, 'colsample_bytree': 0.6343300945092906}. Best is trial 3 with value: 0.9998658747582126.\n",
      "[I 2025-01-28 14:11:27,177] Trial 10 finished with value: 0.9998411258545262 and parameters: {'n_estimators': 500, 'max_depth': 7, 'learning_rate': 0.2895912098135431, 'subsample': 0.8529879001527503, 'colsample_bytree': 0.7525951318822013}. Best is trial 3 with value: 0.9998658747582126.\n",
      "[I 2025-01-28 14:11:28,013] Trial 11 finished with value: 0.9998580814465425 and parameters: {'n_estimators': 216, 'max_depth': 5, 'learning_rate': 0.1346229754201433, 'subsample': 0.5147113280086467, 'colsample_bytree': 0.7285447980198183}. Best is trial 3 with value: 0.9998658747582126.\n",
      "[I 2025-01-28 14:11:29,141] Trial 12 finished with value: 0.9998640532081786 and parameters: {'n_estimators': 323, 'max_depth': 4, 'learning_rate': 0.03717143296688631, 'subsample': 0.684801227590128, 'colsample_bytree': 0.7223966003087396}. Best is trial 3 with value: 0.9998658747582126.\n",
      "[I 2025-01-28 14:11:30,748] Trial 13 finished with value: 0.9998694586939164 and parameters: {'n_estimators': 430, 'max_depth': 5, 'learning_rate': 0.032754277374995595, 'subsample': 0.6832492279017804, 'colsample_bytree': 0.7560385276911048}. Best is trial 13 with value: 0.9998694586939164.\n",
      "[I 2025-01-28 14:11:32,679] Trial 14 finished with value: 0.9998668967579353 and parameters: {'n_estimators': 457, 'max_depth': 6, 'learning_rate': 0.030687631938188156, 'subsample': 0.6948052191848101, 'colsample_bytree': 0.970665689346087}. Best is trial 13 with value: 0.9998694586939164.\n",
      "[I 2025-01-28 14:11:34,799] Trial 15 finished with value: 0.9998599409152081 and parameters: {'n_estimators': 425, 'max_depth': 9, 'learning_rate': 0.023640915804032457, 'subsample': 0.8374369173917077, 'colsample_bytree': 0.9734718436823235}. Best is trial 13 with value: 0.9998694586939164.\n",
      "[I 2025-01-28 14:11:36,739] Trial 16 finished with value: 0.9998613619583837 and parameters: {'n_estimators': 489, 'max_depth': 6, 'learning_rate': 0.048001460161484336, 'subsample': 0.6946495414987619, 'colsample_bytree': 0.9979497280499418}. Best is trial 13 with value: 0.9998694586939164.\n",
      "[I 2025-01-28 14:11:39,005] Trial 17 finished with value: 0.9997696765935131 and parameters: {'n_estimators': 389, 'max_depth': 10, 'learning_rate': 0.012080057141849425, 'subsample': 0.8201913412744226, 'colsample_bytree': 0.8143177347621983}. Best is trial 13 with value: 0.9998694586939164.\n",
      "[I 2025-01-28 14:11:40,505] Trial 18 finished with value: 0.9998649160812128 and parameters: {'n_estimators': 338, 'max_depth': 7, 'learning_rate': 0.02628350106159716, 'subsample': 0.7164519221120125, 'colsample_bytree': 0.678433551158687}. Best is trial 13 with value: 0.9998694586939164.\n",
      "[I 2025-01-28 14:11:42,154] Trial 19 finished with value: 0.9998613031416809 and parameters: {'n_estimators': 428, 'max_depth': 6, 'learning_rate': 0.09094886861030857, 'subsample': 0.8977782396112035, 'colsample_bytree': 0.9355502652240457}. Best is trial 13 with value: 0.9998694586939164.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best XGBoost Parameters: {'n_estimators': 430, 'max_depth': 5, 'learning_rate': 0.032754277374995595, 'subsample': 0.6832492279017804, 'colsample_bytree': 0.7560385276911048}\n",
      "\n",
      "===== XGBoost Performance =====\n",
      "R² Score: 0.9999\n",
      "Time taken: 32.9752 seconds\n",
      "CPU time used: 267.1250 seconds (user + system)\n",
      "Approx. additional RAM used: 40.5078 MB\n",
      "\n",
      "===== Model Comparison =====\n",
      "Metric                    Linear Regression    XGBoost             \n",
      "-----------------------------------------------------------------\n",
      "R² Score                  0.9874               0.9999              \n",
      "Time Taken (s)            0.1055               32.9752             \n",
      "CPU Time Used (s)         0.7969               267.1250            \n",
      "Memory Used (MB)          0.0000               40.5078             \n"
     ]
    }
   ],
   "source": [
    "# Define X and y\n",
    "# -------------------------------------------------------------------\n",
    "# Prepare features (X) and target (y)\n",
    "# -------------------------------------------------------------------\n",
    "# 1. Separate numeric features\n",
    "X_numeric = df[numeric_columns]\n",
    "\n",
    "# 2. Convert categorical columns to string and handle NaNs by filling with 'Missing'\n",
    "df_categorical_str = df[categorical_columns].astype(str).fillna('Missing')\n",
    "\n",
    "# Additionally, replace 'nan' strings resulting from original NaNs with 'Missing'\n",
    "df_categorical_str.replace('nan', 'Missing', inplace=True)\n",
    "\n",
    "# 3. One-hot encode categorical features, including 'Missing' as a category\n",
    "df_one_hot = pd.get_dummies(df_categorical_str, dummy_na=False, drop_first=True)\n",
    "\n",
    "# 4. Concatenate numeric and one-hot-encoded features\n",
    "X = pd.concat([X_numeric, df_one_hot], axis=1)\n",
    "\n",
    "# 5. Define the target variable (y) and sample weights\n",
    "y = df[target_variable]\n",
    "sample_weight = df[weight_column]\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 12. Impute Missing Values in Numeric Features\n",
    "# -------------------------------------------------------\n",
    "# Identify numeric columns in X_numeric\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Initialize SimpleImputer for numeric data\n",
    "numeric_imputer = SimpleImputer(strategy='mean')\n",
    "\n",
    "# Fit and transform numeric features\n",
    "X_numeric_imputed = pd.DataFrame(\n",
    "    numeric_imputer.fit_transform(X_numeric),\n",
    "    columns=X_numeric.columns,\n",
    "    index=X_numeric.index\n",
    ")\n",
    "\n",
    "# Update X_numeric with imputed values\n",
    "X_numeric = X_numeric_imputed\n",
    "\n",
    "# Replace the numeric part in X with imputed data\n",
    "X.update(X_numeric)\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 13. Ensure No NaNs in One-Hot Encoded Features\n",
    "# -------------------------------------------------------\n",
    "# Since we filled NaNs in categorical features with 'Missing' before encoding,\n",
    "# there should be no NaNs in df_one_hot. However, verify just in case.\n",
    "assert not X.isnull().any().any(), \"There are still NaNs in the feature set.\"\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 14. Handle Missing Values in Target Variable (y)\n",
    "# -------------------------------------------------------\n",
    "# Drop rows where target variable is NaN\n",
    "valid_rows = y.notna()\n",
    "X = X[valid_rows]\n",
    "y = y[valid_rows]\n",
    "sample_weight = sample_weight[valid_rows]\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 15. Final Sanity Checks\n",
    "# -------------------------------------------------------\n",
    "print(\"\\nFinal data checks:\")\n",
    "print(f\"Number of samples: {X.shape[0]}\")\n",
    "print(f\"Number of features: {X.shape[1]}\")\n",
    "print(f\"Any NaNs in features: {X.isnull().any().any()}\")\n",
    "print(f\"Any NaNs in target: {y.isnull().any()}\")\n",
    "\n",
    "\n",
    "\n",
    "#########################################################################################################\n",
    "##############################################################################################################################\n",
    "##############################################################################################################################\n",
    "#####Comparing Models\n",
    "###############################################################\n",
    "###############################################################\n",
    "\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 1. Prepare the Dataset (Assuming X and y are already defined)\n",
    "# -------------------------------------------------------\n",
    "# Ensure no NaNs before training\n",
    "X = X.fillna(0)  # Replace NaNs with 0 (Alternative: Impute with mean)\n",
    "y = y.fillna(y.mean())  # Impute target variable if needed\n",
    "\n",
    "# Split dataset for fair comparison\n",
    "X_train, X_test, y_train, y_test, sw_train, sw_test = train_test_split(\n",
    "    X, y, sample_weight, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 2. Measure Initial Resource Usage (Linear Regression)\n",
    "# -------------------------------------------------------\n",
    "process = psutil.Process()\n",
    "start_cpu_times = process.cpu_times()\n",
    "mem_info_start = process.memory_info().rss  # Resident Set Size in bytes\n",
    "start_time = time.time()\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 3. Fit the Linear Regression Model\n",
    "# -------------------------------------------------------\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train, sample_weight=sw_train)\n",
    "lr_r2 = lr_model.score(X_test, y_test, sample_weight=sw_test)\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 4. Measure Resource Usage After Training (Linear Regression)\n",
    "# -------------------------------------------------------\n",
    "end_time = time.time()\n",
    "end_cpu_times = process.cpu_times()\n",
    "mem_info_end = process.memory_info().rss\n",
    "\n",
    "# Calculate differences\n",
    "lr_run_time = end_time - start_time\n",
    "lr_cpu_time_used = (\n",
    "    (end_cpu_times.user + end_cpu_times.system)\n",
    "    - (start_cpu_times.user + start_cpu_times.system)\n",
    ")\n",
    "lr_mem_used = (mem_info_end - mem_info_start) / (1024 * 1024)  # Convert bytes to MB\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 5. Print Linear Regression Results\n",
    "# -------------------------------------------------------\n",
    "print(\"\\n===== Linear Regression Performance =====\")\n",
    "print(f\"R² Score: {lr_r2:.4f}\")\n",
    "print(f\"Time taken: {lr_run_time:.4f} seconds\")\n",
    "print(f\"CPU time used: {lr_cpu_time_used:.4f} seconds (user + system)\")\n",
    "print(f\"Approx. additional RAM used: {lr_mem_used:.4f} MB\")\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 6. Define Optuna Objective Function for XGBoost\n",
    "# -------------------------------------------------------\n",
    "def objective(trial):\n",
    "    \"\"\"Hyperparameter tuning using Optuna\"\"\"\n",
    "    params = {\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 500),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 12),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3, log=True),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n",
    "        \"objective\": \"reg:squarederror\",\n",
    "        \"eval_metric\": \"rmse\",\n",
    "        \"random_state\": 42\n",
    "    }\n",
    "    \n",
    "    model = xgb.XGBRegressor(**params)\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        sample_weight=sw_train,\n",
    "        eval_set=[(X_test, y_test)],\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    pred = model.predict(X_test)\n",
    "    return r2_score(y_test, pred)\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 7. Measure Initial Resource Usage (XGBoost)\n",
    "# -------------------------------------------------------\n",
    "process = psutil.Process()\n",
    "start_cpu_times = process.cpu_times()\n",
    "mem_info_start = process.memory_info().rss  # Resident Set Size in bytes\n",
    "start_time = time.time()\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 8. Run Optuna Hyperparameter Optimization\n",
    "# -------------------------------------------------------\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=20)  # Adjust trials as needed\n",
    "\n",
    "# Best parameters\n",
    "best_params = study.best_params\n",
    "print(\"\\nBest XGBoost Parameters:\", best_params)\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 9. Train Final XGBoost Model with Best Hyperparameters\n",
    "# -------------------------------------------------------\n",
    "xgb_model = xgb.XGBRegressor(**best_params)\n",
    "xgb_model.fit(X_train, y_train, sample_weight=sw_train)\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 10. Evaluate the Model (R² Score)\n",
    "# -------------------------------------------------------\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "xgb_r2 = r2_score(y_test, y_pred_xgb)\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 11. Measure Time and Resource Usage After Training (XGBoost)\n",
    "# -------------------------------------------------------\n",
    "end_time = time.time()\n",
    "end_cpu_times = process.cpu_times()\n",
    "mem_info_end = process.memory_info().rss\n",
    "\n",
    "# Calculate differences\n",
    "xgb_run_time = end_time - start_time\n",
    "xgb_cpu_time_used = (\n",
    "    (end_cpu_times.user + end_cpu_times.system)\n",
    "    - (start_cpu_times.user + start_cpu_times.system)\n",
    ")\n",
    "xgb_mem_used = (mem_info_end - mem_info_start) / (1024 * 1024)  # Convert bytes to MB\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 12. Print XGBoost Results\n",
    "# -------------------------------------------------------\n",
    "print(\"\\n===== XGBoost Performance =====\")\n",
    "print(f\"R² Score: {xgb_r2:.4f}\")\n",
    "print(f\"Time taken: {xgb_run_time:.4f} seconds\")\n",
    "print(f\"CPU time used: {xgb_cpu_time_used:.4f} seconds (user + system)\")\n",
    "print(f\"Approx. additional RAM used: {xgb_mem_used:.4f} MB\")\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 13. Compare Linear Regression vs XGBoost\n",
    "# -------------------------------------------------------\n",
    "print(\"\\n===== Model Comparison =====\")\n",
    "print(f\"{'Metric':<25} {'Linear Regression':<20} {'XGBoost':<20}\")\n",
    "print(\"-\" * 65)\n",
    "print(f\"{'R² Score':<25} {lr_r2:<20.4f} {xgb_r2:<20.4f}\")\n",
    "print(f\"{'Time Taken (s)':<25} {lr_run_time:<20.4f} {xgb_run_time:<20.4f}\")\n",
    "print(f\"{'CPU Time Used (s)':<25} {lr_cpu_time_used:<20.4f} {xgb_cpu_time_used:<20.4f}\")\n",
    "print(f\"{'Memory Used (MB)':<25} {lr_mem_used:<20.4f} {xgb_mem_used:<20.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EDUC99</th>\n",
       "      <th>PARENT1_EDUC</th>\n",
       "      <th>PARENT2_EDUC</th>\n",
       "      <th>TENURE</th>\n",
       "      <th>SEX_2</th>\n",
       "      <th>RACE_200</th>\n",
       "      <th>RACE_300</th>\n",
       "      <th>RACE_650</th>\n",
       "      <th>AGE_bucket_25–34</th>\n",
       "      <th>AGE_bucket_35–44</th>\n",
       "      <th>AGE_bucket_45–54</th>\n",
       "      <th>AGE_bucket_55–64</th>\n",
       "      <th>AGE_bucket_65+</th>\n",
       "      <th>AGE_bucket_&lt;18</th>\n",
       "      <th>VETSTAT_1</th>\n",
       "      <th>VETSTAT_2</th>\n",
       "      <th>PARENT1_AGE_BUCKET_25–34</th>\n",
       "      <th>PARENT1_AGE_BUCKET_35–44</th>\n",
       "      <th>PARENT1_AGE_BUCKET_45–54</th>\n",
       "      <th>PARENT1_AGE_BUCKET_55–64</th>\n",
       "      <th>PARENT1_AGE_BUCKET_65+</th>\n",
       "      <th>PARENT1_AGE_BUCKET_&lt;18</th>\n",
       "      <th>PARENT1_AGE_BUCKET_Missing</th>\n",
       "      <th>PARENT2_AGE_BUCKET_25–34</th>\n",
       "      <th>PARENT2_AGE_BUCKET_35–44</th>\n",
       "      <th>PARENT2_AGE_BUCKET_45–54</th>\n",
       "      <th>PARENT2_AGE_BUCKET_55–64</th>\n",
       "      <th>PARENT2_AGE_BUCKET_65+</th>\n",
       "      <th>PARENT2_AGE_BUCKET_&lt;18</th>\n",
       "      <th>PARENT2_AGE_BUCKET_Missing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>75220</th>\n",
       "      <td>6</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48955</th>\n",
       "      <td>10</td>\n",
       "      <td>11.020831</td>\n",
       "      <td>11.490234</td>\n",
       "      <td>64</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44966</th>\n",
       "      <td>11</td>\n",
       "      <td>11.020831</td>\n",
       "      <td>11.490234</td>\n",
       "      <td>27</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13568</th>\n",
       "      <td>15</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>11.490234</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92727</th>\n",
       "      <td>5</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>11.490234</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       EDUC99  PARENT1_EDUC  PARENT2_EDUC  TENURE  SEX_2  RACE_200  RACE_300  \\\n",
       "75220       6      6.000000     15.000000       2  False     False     False   \n",
       "48955      10     11.020831     11.490234      64   True     False     False   \n",
       "44966      11     11.020831     11.490234      27  False     False     False   \n",
       "13568      15     10.000000     11.490234       0   True      True     False   \n",
       "92727       5      6.000000     11.490234       4  False     False     False   \n",
       "\n",
       "       RACE_650  AGE_bucket_25–34  AGE_bucket_35–44  AGE_bucket_45–54  \\\n",
       "75220     False             False             False             False   \n",
       "48955     False             False             False             False   \n",
       "44966     False             False             False              True   \n",
       "13568     False             False             False             False   \n",
       "92727     False             False             False             False   \n",
       "\n",
       "       AGE_bucket_55–64  AGE_bucket_65+  AGE_bucket_<18  VETSTAT_1  VETSTAT_2  \\\n",
       "75220             False           False            True       True      False   \n",
       "48955             False            True           False       True      False   \n",
       "44966             False           False           False       True      False   \n",
       "13568             False           False           False       True      False   \n",
       "92727             False           False            True       True      False   \n",
       "\n",
       "       PARENT1_AGE_BUCKET_25–34  PARENT1_AGE_BUCKET_35–44  \\\n",
       "75220                     False                      True   \n",
       "48955                     False                     False   \n",
       "44966                     False                     False   \n",
       "13568                     False                     False   \n",
       "92727                     False                      True   \n",
       "\n",
       "       PARENT1_AGE_BUCKET_45–54  PARENT1_AGE_BUCKET_55–64  \\\n",
       "75220                     False                     False   \n",
       "48955                     False                     False   \n",
       "44966                     False                     False   \n",
       "13568                      True                     False   \n",
       "92727                     False                     False   \n",
       "\n",
       "       PARENT1_AGE_BUCKET_65+  PARENT1_AGE_BUCKET_<18  \\\n",
       "75220                   False                   False   \n",
       "48955                   False                   False   \n",
       "44966                   False                   False   \n",
       "13568                   False                   False   \n",
       "92727                   False                   False   \n",
       "\n",
       "       PARENT1_AGE_BUCKET_Missing  PARENT2_AGE_BUCKET_25–34  \\\n",
       "75220                       False                     False   \n",
       "48955                        True                     False   \n",
       "44966                        True                     False   \n",
       "13568                       False                     False   \n",
       "92727                       False                     False   \n",
       "\n",
       "       PARENT2_AGE_BUCKET_35–44  PARENT2_AGE_BUCKET_45–54  \\\n",
       "75220                      True                     False   \n",
       "48955                     False                     False   \n",
       "44966                     False                     False   \n",
       "13568                     False                     False   \n",
       "92727                     False                     False   \n",
       "\n",
       "       PARENT2_AGE_BUCKET_55–64  PARENT2_AGE_BUCKET_65+  \\\n",
       "75220                     False                   False   \n",
       "48955                     False                   False   \n",
       "44966                     False                   False   \n",
       "13568                     False                   False   \n",
       "92727                     False                   False   \n",
       "\n",
       "       PARENT2_AGE_BUCKET_<18  PARENT2_AGE_BUCKET_Missing  \n",
       "75220                   False                       False  \n",
       "48955                   False                        True  \n",
       "44966                   False                        True  \n",
       "13568                   False                        True  \n",
       "92727                   False                        True  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
